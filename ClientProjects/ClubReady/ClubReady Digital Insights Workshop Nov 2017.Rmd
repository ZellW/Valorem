---
title: 'ClubReady Digital Insights Workshop - EDA'
output:
    rmdformats::readthedown:
      highlight: pygments
      code_folding: hide
---

<style type="text/css">
p{ /* Normal  */
   font-size: 14px;
   line-height: 18px;
}
body{ /* Normal  */
   font-size: 14px;
}
td {  /* Table  */
   font-size: 12px;
}
h1 { /* Header 1 */
 font-size: 26px;
 color: #4294ce;
}
h2 { /* Header 2 */
 font-size: 22px;
}
h3 { /* Header 3 */
 font-size: 18px;
}
code.r{ /* Code block */
  font-size: 12px;
}
pre { /* Code block */
  font-size: 12px
}
#table-of-contents h2 {
background-color: #4294ce;
}
#table-of-contents{
background: #688FAD;
}
#nav-top span.glyphicon{
color: #4294ce;
}
#postamble{
background: #4294ce;
border-top: ;
}
</style>

```{r loadLibs1, warning=FALSE, message=FALSE}
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("plyr", "dplyr", "data.table", "xda","ggplot2", "forcats", "readr", "gridExtra",  prompt = FALSE)
#data.table used only for fread
```

# Introduction

## Document Format

This document walks through the initial Exploratory Data Analysis supporting the potential algorithm development to predict different churn models for ClubReady.  The document is organized as follows:

- One of three CSV data files, stores.csv, is explored with detail in the first section
- In the Appendix, the other two data files (User and Class & Services) are explored albeit with less explanatory content
- All of these sections roughly follow the same thought process:
    - Get Data
    - Remove/transform NAs
    - Character to Factors
    - Explore factors with tables and plots
    - Explore numerical data
    - Explore variances
    - Manage duplicate records
    - Data Glimpse

## Client Description

ClubReady LLC operates a Web based club management platform for fitness facilities, fitness individuals, and large corporate chains. It specializes in member management, billing, EFT and POS, and sales process/CRM. The company was incorporated in 2014 and is based in St. Louis, Missouri. 

## Client Business Problem

ClubReady is currently the 3rd largest company in their industry.  The company recognizes the need to take full advantage of their digital assets in an effort to gain deeper knowledge and understanding of customer behaviors.  ClubReady has taken steps in this area to begin analyzing the significant data it captures through its membership software applications, and seeks support to further explore its data assets.  ClubReady reached out to Valorem as a preferred Microsoft partner with expertise in Advanced Analytics, including Azure Machine Learning and the Cortana Intelligence Suite of Azure services.   

ClubReady wants to become *a data-first* company focused on membership and member retention insights gained through an exploration of ClubReady data.

## Client Engagement

On October 3, 2017, ClubReady accepted a Valorem statement of work for a Digital Insight Workshop.  The workshop provided the following deliverables

- Data Assessment and Quality Report 
- Digital Analytics Vision & Roadmap of Actionable Insights 
- Documented Key Priorities 
- Potential Digital Insights Program ROI 
- Recommended and Prioritized Analytics Actions 
- Analytics Roadmap and Estimates 
- Presentation of Next Steps

> As documented later in the report, these deliverables were collapsed into fewer deliverables as agreed during the inital on-site workshop meeting.

## Digital Insights Process

The Digital Insights Workshop Project flow includes:

1. Pre-Work and Agenda
2. On-Site Workshop
3. Analytics Run
4. Present Findings

> Analytics Run is renamed in this document to Exploratory Data Analysis

## Pre-Work and Agenda

On November 20, 2017, Valorem's Project Manager led an introductory pre-workshop Skype Meeting.  Andy Sweet, the ClubReady CTO and Project Sponsor participated with Valorem Data Scientists.  The meeting consisted of:

- Team Introductions
- Project Overview
- Communications Plan
- Q & A

The core project Team Members were identified:

| Team Member | Company & Title |
| --------------| ----------------------------------- |
| Andy Sweet | ClubReady CTO |
| Justin Trusty | ClubReady Data Architect |
| Lauren Crosby | ClubReady Director of Product Management |
| Matt Mercurio | ClubReady Director of Engineering |
| Brad Llewellyn | Valorem Data Scientist |
| Cliff Weaver | Valorem Data Scientist |
| Brian Roselli | Valorem Project Management |

## On-Site Workshop

The on-site workshop was help at ClubReady on November 28 - 29.  The agenda presented at the workshop included:

- Day 1
    - ClubReady vision, goals, priorities
    - What can machine learning do for you?
    - Problem statements 
    - Redefine deliverables
    - Churn Example
    - Data Sources & Definitions
- Day 2
    - Review previous day successes and misses
    - Data Exploration
    - Q&A
    - Time Permitting (Client’s Choice)
    - Introduction to R

During the two-day workshop, the agenda was roughly followed.  Regardless of the path, all the objectives to the workshop were accomplished:

- Understanding ClubReady goals and priorities
- Development of well-formed questions
- Review and Modification to Deliverables and Format
- Access to data
- Selection of data for analysis

### Understanding ClubReady Goals & Priorities

At the start of the on-site workshop, Andy Sweet provided an overview of ClubReady, its FY18 Goals and the mission to become a *data-first* company believing this will provide a strategic advantage over its competitors.  (This section is intentionally kept brief because it is help for Valorem but provides no additional insights from ClubReady.)

### Well-Formed Question Development

The success of any data science project starts with a well-formed question.  A well-formed question is a prerequisite to a project because without it, the project is highly likely to fail.  At a minimum, a well-formed question provides:

A statement of the problem or issue that needs to be solved
Detailed description of the data available for analysis.  This includes data that is not not available.
A description of what ClubReady would like to be able to predict or categorize 
What ClubReady will do when the answer from the last step is available

ClubReady wants to identify what clubs (full service and DIY) are likely to fail based on percentage drop in 
revenue 

> Significant revenue percentage drop needs to be defined - currently defined as 80% drop in revenue from previous month

Member Churn is defined by an individual customer agreement termination with no renewal within 30 days.

ClubReady wants to identify the individual customer propensity at the club level (lowest organization in the hierarchy) to terminate their club agreement.  (This excludes one-time users - ie not club members)

If a customer moves to an chain within the same owner hierarchy, need to check the change table to ID.  So churn becomes:  Agreement ends and not renewed in 30 days or club transfer

### Review and Modification to Diliverables and Format

The Statement of Work proferred the followin goutputs:

- Data Assessment and Quality Report
- Digital Analytics Vision & Roadmap of Actionable Insights
- Documented Key Priorities 
- Potential Digital Insights Program ROI
- Recommended and Prioritized Analytics Actions
- Analytics Roadmap and Estimates
- Presentation of Next Steps

During the workshop, example documentation built using RMarkdown language saved in HTML format was presented.  The ClubReady Team agreed this format was acceptable for all project reporting.  (This document is the result of that agreement.)

### Access to ClubReady Data

On the 2nd day of the workshop, Valorem was granted and verified access to ClubReady data.

### Data Selection

ClubReady reviewed the tables and variables available in the ClubReady database (over 600 tables and 3,000+ fileds).  It was quickly realized a majority of the fields   were sparsely populated.  The Team implemented custom SQL code to identify the sparsity of each variable.  The Team then identified the initial set of candidate data ClubReady believed to be important to answer the well-formed questions.

#### Data Caveats & Assumptions

- There was no method to identify when data was populated.  If a column was 60% dense, the filed would not have been selected even if that variable is 100% dense in the last year or two.
- There is no guarantee all impactful variables were identified.  Reviewing a large dataset with a small Team does not ensure all important variables were included in the data used for modeling.
- Team determined the latest 2 years of data would be used for the project.  It was in this period ClubReady experienced significant growth.

#### Reminders (delete before client presentation)

Personal Training (PT) Club - buy services via credits.  No agreement.  Buys services for like 6 sessions.  If Number of services = 0, wait 30 days to become churn
This is a different customer experience and behavior. 

If both, agreement trumps PT session count

Membership - agreement on file

### Miscellaneous Workshop Notes TOBE DELETED

- OK to use models that are black boxes - confirm
- Clubs that transfer to ClubReady includes active and inactive users.  Does ClubReady increase or decrease churn?  Does Valorem treat these customers differently from a churn prov?
- Some stores only use CR CRM Product and nothing else - need to be able to filter CRM Stores only
- Remember - user types need to be filtered to diff between staff and customers

# Exploratory Data Analysis

This is the tactical execution results of the Exploratory Data Analysis process.  Recall the `stores.csv` data file is explored first in detail followed by `ClassesService.csv` and `users.csv` with less commentary content.

## Get Data

Working with ClubReady, Valorem developed SQL scripts capturing raw data ClubReady data in csv format. These scripts can be found as part of the `[crsql01c.clubready.local].[Reports].[ML].[ChurnScripts]` stored procedure.

```{r loadData, echo=FALSE, message=FALSE,warning=FALSE, results='hide'}
stores <- read_csv("C:/Users/cweaver/Downloads/Stores.csv", 
    col_types = cols(showIDphoto = col_integer(), 
        showaboutus = col_integer(), showactivity = col_integer(), 
        showarticles = col_integer(), showbalances = col_integer(), 
        showcusttodo = col_integer(), showdiscussion = col_integer(), 
        showfastfacts = col_integer(), showfitevals = col_integer(), 
        showgoals = col_integer(), showjournal = col_integer(), 
        shownews = col_integer(), shownutrition = col_integer(), 
        showphotos = col_integer(), showprogreport = col_integer(), 
        showprovtodo = col_integer(), showpurchhistory = col_integer(), 
        showscheduling = col_integer(), showstaffbios = col_integer()))
```

The first csv, `stores`, returned `r dim(stores[1])` records with `r dim(stores[2])` variables.  Of the `r dim(stores)[2]` variables, `r nrow(stores %>% select_if(is.character))` is a `character` type and `r nrow(stores %>% select_if(is.numeric))` are `numeric`.

> Valorem learned from ClubReady some variables have no current business value.  These have been removed from the working dataset.

```{r}
deletedVars <- names(stores[grepl("^show", colnames(stores))])
deletedVars <- ldply(deletedVars, data.frame)#convert list to DF
names(deletedVars) <- "Deleted_Variables"
stores  <-  stores[, !grepl("^show", colnames(stores))]
```

The `r nrow(deletedVars)` removed variables are:
```{r}
deletedVars
```

## Categorical Variables

Lets look at the categorical variables first:

```{r}
charSummary(stores)
```

We learn the only categorical variable is `Status`.  `Status` is a factor with several levels. 

```{r}
stores <- stores %>% mutate_if(is.character, as.factor)
#charSummary(stores)
table(stores$Status)
ggplot(stores, aes(fct_infreq(Status))) + geom_bar() + xlab("ClubReady Status Code") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

ClubReady provided direction on how to manage `Active`, `Inactive`, and `Cancel`:

*Inactive is a store that is no longer with ClubReady.  Most likely left to go to competitor.*
*Cancel is a store that was in the process of being setup and for some reason stopped.*
*Ignore cancel.*

Remove records where `Status` is not either `Active` or `Inactive`.

```{r}
#starts with 5321, end with 4288 records
stores <-  filter(stores, Status == 'Active' | Status == 'Inactive')
table(stores$Status)
stores$Status <- factor(stores$Status)
table(stores$Status)
```

After removing the records associated with `Status` fields that are not needed, `r nrow(stores)` records remain.

## Numerical Data

Lets review the numerical data.  Pay attention to the missing data percentage in shown in the right-most column below.  (Note, only showing the first 20 of the `r nrow(stores %>% select_if(is.numeric))` numerical variables.

```{r storeVarTypeNames}
myNumSum <- numSummary(stores)[, c(1,7,8,16,17)]
myNumSum <- tibble::rownames_to_column(myNumSum)
names(myNumSum)[5] <- "missCNT"
names(myNumSum)[1] <- "Variable_Name"
myNumSum <- arrange(myNumSum, desc(n))
head(myNumSum, 20)
```

Good, no missing data!

Examine the numerical data using plotting to illustrate interesting distributions.

```{r plotsNumeric, message=FALSE, warning=FALSE}
library(purrr)
library(tidyr)

cntNumNames <- length(select(select_if(stores,is.numeric), -StoreId))
#Make plots max 6 at a time - change if needed
maxPlot = 6
loopCnt <- cntNumNames %/% maxPlot
remainder <- cntNumNames %% maxPlot

myLoop_DF <- data.frame(x = seq(1, cntNumNames-remainder, by = maxPlot), y = seq(6, cntNumNames, by = maxPlot))
myLoopMax <- max(myLoop_DF)

for(i in 1:nrow(myLoop_DF)){
  myplot <- select(select_if(stores,is.numeric), -StoreId)[myLoop_DF[i,1]:myLoop_DF[i,2]]%>% gather() %>% ggplot(aes(value)) +
      facet_wrap(~ key, scales = "free") + geom_histogram() #+  geom_density()
  print(myplot)
}
```

Most of the plots above are not very interesting but there are a few that we might to revisit individually including `Amenities`, `Forms`, and `NonRequiredForms`.

```{r}
p1 <- ggplot(filter(stores, Amenities > 0), aes(Amenities)) + geom_bar() + ggtitle("Amenties > 0")
p2 <- ggplot(filter(stores, Forms > 0), aes(Amenities)) + geom_bar() + ggtitle("Forms > 0")
p3 <- ggplot(filter(stores, NonRequiredForms > 0), aes(Amenities)) + geom_bar() + ggtitle("NonRequiredForms > 0")
grid.arrange(p1, p2, p3, ncol=3)
```

### Variability

Evaluate how much variability there is in each numerical variable.

```{r message=FALSE, warning=FALSE}
#Col 1 -s StoreId, 20 is Status
myVariance <- as.data.frame(apply(stores[,-c(1,20)], 2, var))
myVariance <- tibble::rownames_to_column(myVariance)
names(myVariance)[2] <- "Variance"
myVariance <-  myVariance %>% mutate(Variance2 = ifelse(Variance == 0, "No", "Yes"))
table(myVariance$Variance2)
```

Because `r table(myVariance$Variance2)[1]` variables have no variance - all the values are the same, they can be removed from the working dataset.  If there are no differences in a column, it is of no use in the development of an algorithm.  The variables to be removed because there is no variance are:

```{r}
VarNames <- myVariance %>% filter(Variance > 0) %>% select(rowname)
zeroVarNames <- myVariance %>% filter(Variance == 0) %>% select(rowname)
stores <- stores %>% select(StoreId, Status, unlist(VarNames))
zeroVarNames
```

### Outlier Detection

In the working dataset, there is one variable, `TotalRevenue` that should be evaluated to identify any potential outlier.  There are many way to visualize outliers.  Boxplots are the most commonly used visualization.

```{r}
out2 <- ggplot(stores, aes(x = "", y = TotalRevenue)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=4) + 
  scale_y_continuous(labels = scales::dollar)
```

There are potential outliers.  **ClubReady must advise Valorem on the legitamcy of these values.**  

Here is a list of the highest 25 TotalRevenue records:

```{r}
tmpRev <- arrange(stores, desc(TotalRevenue)) %>% select(TotalRevenue)
tmpRev <- as.data.frame(head(scales::dollar(tmpRev$TotalRevenue), 25))
names(tmpRev) <- "Total_Revenue"
tmpRev
```

```{r}
q <- quantile(stores$TotalRevenue)
stores$Qcut <- cut(stores$TotalRevenue, q)
levels(stores$Qcut) <- c("Q1", "Q2", "Q3", "Q4")
summary(stores$Qcut)[1:4]
```

It is curious, perhaps suspect, that the number of records in the 2nd, 3rd and 4th quartiles are the same.  **This too needs to be evaluated.**

### Duplicates

Lastly, check for duplicate records.  In this case, none are found because each record has a unique `StoreId` value.  Without this variable, you would find `{r nrow(stores[,-1]) - nrow(unique(stores[,-1]))`} duplicates. (Interesting in its own right.)

```{r dupes}
# Duplicate Records
cat("The number of duplicated rows is", nrow(stores) - nrow(unique(stores)))

# if(nrow(stores) - nrow(unique(stores)) > 0){
#   head(stores[duplicated(stores),])
#   stores <- stores[!duplicated(stores),]
# }
```

### Data Overview

The working dataset has been initially scrubbed and evaluated.  Take time to review and learn about the data.

The plots below illustrate how often many of the ClubReady configuration options are turned on.

First examine the variable names that start with `Integration`.

```{r}
myColTotal <- as.data.frame(colSums(Filter(is.numeric, stores)))
myColTotal <- tibble::rownames_to_column(myColTotal)
names(myColTotal)[1] <- "Variable_Name"
names(myColTotal)[2] <- "Sum_of_Variable"
myColTotal <- filter(myColTotal, !Variable_Name %in% c("StoreId", "TotalRevenue", "Amenities"))
myColTotal$Variable_Name <- as.factor(myColTotal$Variable_Name)
myColTotal <- myColTotal %>% arrange(desc(Sum_of_Variable))

ggplot(myColTotal %>% filter(Variable_Name %like% "Integration"), aes(x=Variable_Name, y=Sum_of_Variable)) + 
  geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("Variable Name") + ylab("Number of Times Option Selected")
```

Six options appear to be much more popular than the others:

1. Listen360
2. Surveys
3. Club Management System
4. Rewards Program
5. Perkville
6. Data Trak

Below we find that most checkins occur between 8-11AM and 4-7PM local time.  (Need to confirm)

```{r}
ggplot(myColTotal %>% filter(Variable_Name %like% "Checkins_H" ), aes(x=Variable_Name, y=Sum_of_Variable)) + 
  geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("Variable Name") + ylab("Number of Times Option Selected")
```

Lastly, Monday, Tuesday and Wednesday have the most checkins during the week.

```{r}
ggplot(myColTotal %>% filter(!Variable_Name %like% "Checkins_H", Variable_Name %like% "Checkins_"), 
       aes(x=Variable_Name, y=Sum_of_Variable)) + 
  geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("Variable Name") + ylab("Number of Times Option Selected")
```

## Data Glimpse

Here is what the resulting working dataset looks like.  We are left with `r nrow(stores)` records and `r ncol(stores)` (we began the journey with 5321 records and 88 variables).

```{r datatablestores}
glimpse(stores)
```

### Data Consolidation

### Variable Selection

## Present Findings

# Risks and Assumptions

# Appendix

```{r clearObjectsApp1, echo=FALSE}
rm(list= ls())
```

In the Appendix, the ClubReady Classes and Services Data and the User Data is explored.  The EDAs below follow the same patterns as the EDA of `Store` data above.

## EDA - Classes & Services Data

### Get Data

```{r loadClassesServices, message=FALSE, warning=FALSE}
#Get Data
Classes_Services <- read_csv("C:/Users/cweaver/Downloads/Classes_Services.csv", 
                   col_types = cols(AvailablePIF = col_integer(), 
                      ByPerson = col_integer(), CanSeeInstructor = col_integer(), 
                      CancellationHrs = col_integer(), 
                      ClassMins = col_integer(), CustSelfBook = col_integer(), 
                      Disabled = col_integer(), EmailReminders = col_integer(), 
                      HalfHour = col_integer(), MultipleInstructors = col_integer(), 
                      MustHaveCredit = col_integer(), MustPreBook = col_integer(), 
                      NumPerClass = col_integer(), OnTheHour = col_integer(), 
                      QuarterPast = col_integer(), QuarterTill = col_integer(), 
                      RescheduleDeadline = col_integer(), 
                      RuleCustomers = col_integer(), RuleFrontDesk = col_integer(), 
                      SMSReminders = col_integer(), ServicesId = col_integer(), 
                      ShowPublic = col_integer(), StandardPrice = col_integer()), 
                   na = "NA")

myData <- Classes_Services
rm(Classes_Services)
```

`ClassesServices.csv` returned `r dim(myData[1])` records with `r dim(myData[2])` variables.  Of the `r dim(myData)[2]` variables, `r nrow(myData %>% select_if(is.character))` is a `character` type and `r nrow(myData %>% select_if(is.numeric))` are `numeric`.

```{r}
glimpse(myData)
```

### Remove NA

Just as we experienced before, must remove the `NAs` with 0:

```{r}
myData <- myData %>%  mutate_if(is.integer, funs(replace(., is.na(.), 0)))
myData <- myData %>%  mutate_if(is.double, as.integer)
glimpse(myData)
```

That looks much better!

### Character to Factors

Change the variable `Type` from a character to a factor.
```{r}
myData <- myData %>% mutate_if(is.character, as.factor)
class(myData$Type)
```

### Explore Factors

```{r}
charSummary(myData)
```

```{r}
myData_factor <- myData %>% select_if(is.factor)
#myData_num <- myData %>% select_if(is.numeric)

for(i in 1:length(myData_factor)){
  print(names(myData_factor[i]))
  print(table(myData_factor[i]))
}

for(i in 1:length(myData_factor)){
  print(ggplot(myData_factor, aes_string(names(myData_factor[i]))) + geom_bar())
}
```

**Uncertain how to define Class and Service - check with ClubReady**

### Numerical Data

```{r}
myNumSum <- numSummary(myData)[, c(1,7,8,16,17)]
myNumSum <- tibble::rownames_to_column(myNumSum)
names(myNumSum)[5] <- "missPCT"
names(myNumSum)[1] <- "Variable_Name"
myNumSum <- arrange(myNumSum, desc(missPCT))
head(myNumSum, 20)
```

Good, no missing data!

#### Variances

```{r}
myVariance <- as.data.frame(apply(myData[,-c(1)], 2, var))
myVariance <- tibble::rownames_to_column(myVariance)
names(myVariance)[2] <- "Variance"
myVariance <-  myVariance %>% mutate(Variance2 = ifelse(Variance == 0, "No", "Yes"))
table(myVariance$Variance2)
```
All the variables have a variance > 0.

```{r}
if(table(myVariance$Variance2)[1] > 0){
  filter(myVariance, Variance2 == "No")
  VarNames <- myVariance %>% filter(Variance > 0) %>% select(rowname)
  myData <- myData %>% select(StoreId, unlist(VarNames))
}
```

#### Duplicate Records
cat("The number of duplicated rows is", nrow(myData) - nrow(unique(myData)))

```{r showDupes}
myData[duplicated(myData),]
```

> Ask ClubReady if these should be removed

```{r eval=FALSE}
if(nrow(myData) - nrow(unique(myData)) > 0){
  head(myData[duplicated(myData),])
  myData <- myData[!duplicated(myData),]
}
```

### Data Glimpse

```{r}
glimpse(myData)
```

## EDA - User Data

```{r clearObjectsApp2, echo=FALSE}
rm(list= ls())
```

### Get Data

```{r message=FALSE, warning=FALSE}
Users <- read_csv("C:/Users/cweaver/Downloads/Users/Users.csv", col_types = cols(StoreId = col_integer()), progress = FALSE)
myData <- Users
rm(Users)
```

`Users.csv` returned `r dim(myData[1])` records with `r dim(myData[2])` variables.  Of the `r dim(myData)[2]` variables, `r nrow(myData %>% select_if(is.character))` is a `character` type and `r nrow(myData %>% select_if(is.numeric))` are `numeric`.

```{r}
glimpse(myData)
```

### Remove NA

There do not appear to be as many `NAs` as we have seen before.  This time they appear prevalent in the `StoreId` variable.  Also note `NULL` in the `Gender` field.

```{r message=FALSE, warning=FALSE}
myData <- myData %>%  mutate_if(is.integer, funs(replace(., is.na(.), 0)))#changes int to dbl
myData[,-41] <- myData %>%  mutate_if(is.double, as.integer)#return to int
glimpse(myData$StoreId)
```

`StoreId` looks better now.

### Character to Factors

`Gender` and `UserType` are character variables.  Change them to factors.

```{r}
myData <- myData %>% mutate_if(is.character, as.factor)
charSummary(myData)
myData_factor <- myData %>% select_if(is.factor)
```

Note `Gender` appears to have many missing values.  These will be managed a bit later

#### Tables for the Factors

Examine the factors in the working dataset.

```{r}
for(i in 1:length(myData_factor)){
  print(names(myData_factor[i]))
  print(table(myData_factor[i]))
}
rm(myData_factor)
```

There is much work to do on the `Gender` variable.  Will also choose the appropriate `UserType` values for modeling.

#### User Factor - Gender

The values in `Gender` are varied.  These will need to be collapsed into a couple of factor levels.
```{r}
myData %>% group_by(Gender) %>% summarize(Unique_Values = n()) %>% arrange(desc(Unique_Values))
ggplot(myData, aes(fct_infreq(Gender))) + geom_bar() + xlab(paste("ClubReady Subset - ", names(myData)[1])) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
levels(myData$Gender)[levels(myData$Gender) == "F"] <- "Female"
levels(myData$Gender)[levels(myData$Gender) == "female"] <- "Female"
levels(myData$Gender)[levels(myData$Gender) == "f"] <- "Female"

levels(myData$Gender)[levels(myData$Gender) == "M"] <- "Male"
levels(myData$Gender)[levels(myData$Gender) == "male"] <- "Male"
levels(myData$Gender)[levels(myData$Gender) == "m"] <- "Male"

myData %>% group_by(Gender) %>% summarize(Unique_Values = n()) %>% arrange(desc(Unique_Values))
```

This looks better but there are still suspect values.  We will remove:

- All the `Gender` value counts that are small will be removed.  This affects everything from `U` and below in the table above.
- It is reasonable to assume `Gender` is an informative variable in churn modeling.  Valorem will initially remove the `NULL` values from `Gender`.  **Note to Brad**

```{r}
myData <- filter(myData, Gender == "Female" | Gender == "Male")
myData$Gender <- factor(myData$Gender)

ggplot(myData, aes(fct_infreq(Gender))) + geom_bar() + xlab("ClubReady Subset - Gender") +
  scale_y_continuous(labels = scales::comma)
```

#### User Factor - UserType

```{r}
myData %>% group_by(UserType) %>% summarize(Unique_Values = n()) %>% arrange(desc(Unique_Values))
ggplot(myData, aes(fct_infreq(UserType))) + geom_bar() + xlab(paste("ClubReady Subset - ", names(myData)[2])) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_y_continuous(labels = scales::comma)
```

ClubReady confirmed Valorem to use:

- ClubClient     
- DeletedClubClient
- ClubClientTemporary
- DeletedClubAdmin
- ClubAdmin
- CorpAdmin          

```{r}
myData <- filter(myData, UserType == 'ClubClient' | UserType == 'DeletedClubClient' | UserType == 'ClubAdmin' | UserType == 'ClubTrainer' | UserType == 'DeletedClubTrainer' | UserType == 'ClubClientTemporary')
myData$UserType <- factor(myData$UserType)

ggplot(myData, aes(fct_infreq(UserType))) + geom_bar() + xlab("ClubReady Subset - UserType") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + scale_y_continuous(labels = scales::comma)
```

Given the distribution above, Valorem may remove the infrequently used `UserType` values.  **Note to Brad**

### Numerical Data

> Because of the large number of `User` records, a random sample is selected in the code below.

```{r}
myNumSum <- numSummary(sample_frac(myData, .3))[, c(1,7,8,16,17)]
myNumSum <- tibble::rownames_to_column(myNumSum)
names(myNumSum)[5] <- "missPCT"
names(myNumSum)[1] <- "Variable_Name"
myNumSum <- arrange(myNumSum, desc(missPCT))
head(myNumSum, 20)
```

No missing data is in the working dataset.

#### Variance

```{r}
#Do not include UserId, StoreId, Gender, UserType, TotalSpent
myVariance <- as.data.frame(apply(myData[,-c(1,2,4,5,41)], 2, var))
myVariance <- tibble::rownames_to_column(myVariance)
names(myVariance)[2] <- "Variance"
myVariance <-  myVariance %>% mutate(Variance2 = ifelse(Variance == 0, "No", "Yes"))
table(myVariance$Variance2)
```

Because `r table(myVariance$Variance2)[1]` variables have no variance - all the values are the same, they can be removed from the working dataset.  If there are no differences in a column, it is of no use in the development of an algorithm.  The variables to be removed because there is no variance are:

```{r}
if(table(myVariance$Variance2)[1] > 0){
  VarNames <- myVariance %>% filter(Variance > 0) %>% select(rowname)
  zeroVarNames <- myVariance %>% filter(Variance == 0) %>% select(rowname)
  myData <- myData %>% select(UserId, StoreId, Gender, TotalSpent,  unlist(VarNames))
  zeroVarNames
}
```

#### Outlier Detection

In the working dataset, there is one variable, `TotalSpent` that should be evaluated to identify any potential outlier.  There are many way to visualize outliers.  While boxplots are the most commonly used visualization, because the number of records is large, plotting is not an optimal reporting option - it takes a long time to plot millions of records.

Comparing the opposite ends of `TotalSpent` produces interesting information:

```{r eval=FALSE, echo=FALSE}
out3 <- ggplot(myData, aes(x = "", y = TotalSpent)) + geom_boxplot(outlier.color="red", outlier.shape=8, outlier.size=4) + 
  scale_y_continuous(labels = scales::dollar)
```

```{r}
tmpRevDesc <- arrange(myData, desc(TotalSpent)) %>% select(TotalSpent)
tmpRevDesc <- tmpRevDesc[1:25,]
tmpRevDesc <- as.data.frame(scales::dollar(tmpRevDesc$TotalSpent))
names(tmpRevDesc) <- "Total_Spent"

tmpRevAsc <- arrange(myData, TotalSpent) %>% select(TotalSpent)
tmpRevAsc <- tmpRevAsc[1:25,]
tmpRevAsc <- as.data.frame(scales::dollar(tmpRevAsc$TotalSpent))
names(tmpRevAsc) <- "Total_Spent"

knitr::kable(list(tmpRevDesc, tmpRevAsc))
```

The highest `TotalSPent` value is `[r tmpRevDesc[1,]]` and the lowest value is `r tmpRevAsc[1,]`.  If these extreme values are aligned with the business, **ClubReady will need to determine**.

#### Duplication

```{r}
cat("The number of duplicated rows is", nrow(myData) - nrow(unique(myData)))
if((nrow(myData) - nrow(unique(myData)))>0) myData[duplicated(myData),]
```

```{r eval=FALSE}
if(nrow(myData) - nrow(unique(myData)) > 0){
  head(myData[duplicated(myData),])
  myData <- myData[!duplicated(myData),]
}
```

Good news - no duplicate records.

### Data Glimpse

Here is what the resulting working dataset looks like.  We are left with `r nrow(myData)` records and `r ncol(myData)`.

```{r}
glimpse(myData)
```